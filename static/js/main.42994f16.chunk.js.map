{"version":3,"sources":["img/teaser.png","img/digits.png","img/32x32.png","img/digitLengthDist.png","img/individualDigitDist.png","img/gray.png","img/conv.png","img/max-pooling.png","img/fully-connected.png","img/oneHot.png","img/softmax.png","img/model.png","img/train.png","img/epoch.png","img/correct.png","img/wrong.png","img/references.png","img/bruce.png","img/tiantongli.png","img/yiqin.png","components/Header/Header.js","components/Grid/GridContainer.js","components/Grid/GridItem.js","components/Card/cardStyle.js","components/Card/Card.js","components/Card/cardBodyStyle.js","components/Card/CardBody.js","components/Card/material-kit-react.js","components/TeamDescription/imageStyles.js","components/TeamDescription/teamStyles.js","components/TeamDescription/TeamDescription.js","pages/Landing/Landing.js","pages/Proposal/Proposal.js","pages/MidtermUpdate/MidtermUpdate.js","pages/FinalUpdate/FinalUpdate.js","pages/ProjectVideo/ProjectVideo.js","pages/References/References.js","App.js","index.js"],"names":["module","exports","ElevationScroll","props","children","window","trigger","useScrollTrigger","disableHysteresis","threshold","target","undefined","React","cloneElement","elevation","useStyles","makeStyles","theme","fab","alignItems","image","height","width","link","textDecoration","color","button","textTransform","rightJustify","marginLeft","marginRight","leftJustify","Header","classes","Fragment","CssBaseline","AppBar","Toolbar","classeName","to","className","Button","Typography","Box","display","flexDirection","justifyContent","p","grid","GridContainer","rest","Grid","container","defaultProps","position","minHeight","paddingRight","paddingLeft","flexBasis","GridItem","item","cardStyle","card","border","marginBottom","marginTop","borderRadius","background","boxShadow","minWidth","wordWrap","fontSize","transition","cardPlain","cardCarousel","overflow","styles","Card","plain","carousel","cardClasses","classNames","cardBodyStyle","cardBody","padding","flex","CardBody","cardBodyClasses","title","maxWidth","margin","paddingTop","borderTop","fontFamily","fontWeight","lineHeight","imagesStyles","imgFluid","imgRounded","imgRoundedCircle","imgRaised","imgGallery","imgCardTop","borderTopLeftRadius","borderTopRightRadius","imgCardBottom","borderBottomLeftRadius","borderBottomRightRadius","imgCard","imgCardOverlay","top","right","bottom","left","teamStyle","section","textAlign","imagesStyle","itemGrid","cardTitle","smallTitle","description","justifyCenter","socials","transform","margin5","Description","imageClasses","variant","xs","sm","md","src","require","alt","href","wrapper","titleFormat","paddingBottom","titleParagraphFormat","imageFormat","boxFormat","Landing","align","mainFig","lateTitleFormat","titleParagraphFormat2","Proposal","tagChange","MidtermUpdate","teaser","cropped","digitLengthDist","individualDist","gray","conv","pool","fc","imageFormat2","imageFormat3","FinalUpdate","oneHot","softmax","model","train","epoch","correct","wrong","ProjectVideo","paragraphFormat","References","ref","createMuiTheme","palette","primary","main","secondary","contrastText","contrastThreshold","tonalOffset","typography","join","App","ThemeProvider","exact","path","component","render","Component","ReactDOM","basename","process","document","getElementById"],"mappings":";oGAAAA,EAAOC,QAAU,IAA0B,oC,iBCA3CD,EAAOC,QAAU,k0Y,mBCAjBD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,6C,mBCA3CD,EAAOC,QAAU,IAA0B,iD,mBCA3CD,EAAOC,QAAU,IAA0B,kC,mBCA3CD,EAAOC,QAAU,IAA0B,kC,mBCA3CD,EAAOC,QAAU,IAA0B,yC,mBCA3CD,EAAOC,QAAU,IAA0B,6C,mBCA3CD,EAAOC,QAAU,IAA0B,oC,mBCA3CD,EAAOC,QAAU,IAA0B,qC,mBCA3CD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,qC,mBCA3CD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,wC,uDCA3CD,EAAOC,QAAU,IAA0B,mC,mBCA3CD,EAAOC,QAAU,IAA0B,wC,mBCA3CD,EAAOC,QAAU,IAA0B,mC,yOCa3C,SAASC,EAAgBC,GAAQ,IACvBC,EAAqBD,EAArBC,SAAUC,EAAWF,EAAXE,OAIZC,EAAUC,YAAiB,CAC/BC,mBAAmB,EACnBC,UAAW,EACXC,OAAQL,EAASA,SAAWM,IAG9B,OAAOC,IAAMC,aAAaT,EAAU,CAClCU,UAAWR,EAAU,EAAI,IAa7B,IAAMS,EAAYC,aAAW,SAACC,GAAD,MAAY,CACvCC,IAAK,CACHC,WAAY,UAEdC,MAAO,CACLC,OAAQ,OACRC,MAAO,MAETC,KAAM,CACJC,eAAgB,OAChBC,MAAO,QAETC,OAAQ,CACNC,cAAe,OACfF,MAAO,WAETG,aAAc,CACZC,WAAY,OACZC,YAAa,MAEfC,YAAa,CACXD,YAAa,OACbD,WAAY,UAID,SAASG,EAAO7B,GAC7B,IAAM8B,EAAUlB,IAChB,OACE,kBAAC,IAAMmB,SAAP,KACE,kBAACC,EAAA,EAAD,MACA,kBAACjC,EAAoBC,EACnB,kBAACiC,EAAA,EAAD,CAAQX,MAAO,aACb,kBAACY,EAAA,EAAD,KACE,6BAASC,WAAYL,EAAQF,aACzB,kBAAC,IAAD,CAAMQ,GAAG,IAAIC,UAAWP,EAAQV,MAC9B,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QAC3B,kBAACgB,EAAA,EAAD,CAAYjB,MAAQ,WAApB,2CAIN,6BAASe,UAAaP,EAAQL,cAC5B,kBAACe,EAAA,EAAD,CAAKC,QAAQ,OAAOC,cAAc,MAAMC,eAAe,iBACvD,kBAACH,EAAA,EAAD,CAAKI,EAAK,GACR,kBAAC,IAAD,CAAMR,GAAG,YAAYC,UAAWP,EAAQV,MACtC,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QACzB,kBAACgB,EAAA,EAAD,oBAIN,kBAACC,EAAA,EAAD,CAAKI,EAAK,GACR,kBAAC,IAAD,CAAMR,GAAG,iBAAiBC,UAAWP,EAAQV,MAC3C,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QACzB,kBAACgB,EAAA,EAAD,0BAIN,kBAACC,EAAA,EAAD,CAAKI,EAAK,GACR,kBAAC,IAAD,CAAMR,GAAG,eAAeC,UAAWP,EAAQV,MACzC,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QACzB,kBAACgB,EAAA,EAAD,wBAIN,kBAACC,EAAA,EAAD,CAAKI,EAAK,GACR,kBAAC,IAAD,CAAMR,GAAG,gBAAgBC,UAAWP,EAAQV,MAC1C,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QACzB,kBAACgB,EAAA,EAAD,yBAIN,kBAACC,EAAA,EAAD,CAAKI,EAAK,GACR,kBAAC,IAAD,CAAMR,GAAG,cAAcC,UAAWP,EAAQV,MACxC,kBAACkB,EAAA,EAAD,CAAQD,UAAWP,EAAQP,QACzB,kBAACgB,EAAA,EAAD,2BASd,kBAACL,EAAA,EAAD,O,sCCzGAtB,EAAYC,YARH,CACbgC,KAAM,CACJlB,YAAa,QACbD,WAAY,QACZP,MAAO,UAMI,SAAS2B,EAAc9C,GACpC,IAAM8B,EAAUlB,IACRX,EAAiCD,EAAjCC,SAAUoC,EAAuBrC,EAAvBqC,UAAcU,EAFW,YAEF/C,EAFE,0BAG3C,OACE,kBAACgD,EAAA,EAAD,eAAMC,WAAS,GAAKF,EAApB,CAA0BV,UAAWP,EAAQe,KAAO,IAAMR,IACvDpC,GAKP6C,EAAcI,aAAe,CAC3Bb,UAAW,ICtBb,IAWMzB,EAAYC,YAXH,CACbgC,KAAM,CACJM,SAAU,WACVhC,MAAO,OACPiC,UAAW,MACXC,aAAc,OACdC,YAAa,OACbC,UAAW,UAMA,SAASC,EAASxD,GAC/B,IAAM8B,EAAUlB,IACRX,EAAiCD,EAAjCC,SAAUoC,EAAuBrC,EAAvBqC,UAAcU,EAFM,YAEG/C,EAFH,0BAGtC,OACE,kBAACgD,EAAA,EAAD,eAAMS,MAAI,GAAKV,EAAf,CAAqBV,UAAWP,EAAQe,KAAO,IAAMR,IAClDpC,GAKPuD,EAASN,aAAe,CACtBb,UAAW,I,YCHIqB,EA5BC,CACdC,KAAM,CACJC,OAAQ,IACRC,aAAc,OACdC,UAAW,OACXC,aAAc,MACdzC,MAAO,sBACP0C,WAAY,OACZ7C,MAAO,OACP8C,UACE,sGACFd,SAAU,WACVV,QAAS,OACTC,cAAe,SACfwB,SAAU,IACVC,SAAU,aACVC,SAAU,UACVC,WAAY,oBAEdC,UAAW,CACTN,WAAY,cACZC,UAAW,QAEbM,aAAc,CACZC,SAAU,WCZV5D,EAAYC,YAAW4D,GAEd,SAASC,EAAK1E,GAAQ,IAAD,EAC5B8B,EAAUlB,IACRyB,EAAkDrC,EAAlDqC,UAAWpC,EAAuCD,EAAvCC,SAAU0E,EAA6B3E,EAA7B2E,MAAOC,EAAsB5E,EAAtB4E,SAAa7B,EAFf,YAEwB/C,EAFxB,6CAG5B6E,EAAcC,KAAU,mBAC3BhD,EAAQ6B,MAAO,GADY,cAE3B7B,EAAQwC,UAAYK,GAFO,cAG3B7C,EAAQyC,aAAeK,GAHI,cAI3BvC,OAA0B7B,IAAd6B,GAJe,IAM9B,OACE,uCAAKA,UAAWwC,GAAiB9B,GAC9B9C,GCzBP,IAOiB8E,EAPK,CAClBC,SAAU,CACRC,QAAS,qBACTC,KAAM,aCSNtE,EAAYC,YAAW4D,GAEd,SAASU,EAASnF,GAAQ,IAAD,EAChC8B,EAAUlB,IACRyB,EAAiCrC,EAAjCqC,UAAWpC,EAAsBD,EAAtBC,SAAa8C,EAFM,YAEG/C,EAFH,0BAGhCoF,EAAkBN,KAAU,mBAC/BhD,EAAQkD,UAAW,GADY,cAE/B3C,OAA0B7B,IAAd6B,GAFmB,IAIlC,OACE,uCAAKA,UAAW+C,GAAqBrC,GAClC9C,G,WCsIDoF,GA5HS,2BAPQ,CACrBhC,aAAc,OACdC,YAAa,OACb3B,YAAa,OACbD,WAAY,OACZP,MAAO,SAEM,IAEb,4BAA6B,CAC3BmE,SAAU,SAEZ,4BAA6B,CAC3BA,SAAU,SAEZ,4BAA6B,CAC3BA,SAAU,SAEZ,6BAA8B,CAC5BA,SAAU,YA2DS,aACrBhE,MAAO,OACP0C,WAAY,4CAfW,CACvBC,UACE,yHAgBmB,aACrB3C,MAAO,OACP0C,WAAY,4CAxBW,CACvBC,UACE,yHAyBkB,aACpB3C,MAAO,OACP0C,WAAY,4CArBU,CACtBC,UACE,yHAsBgB,aAClB3C,MAAO,OACP0C,WAAY,4CAtCQ,CACpBC,UACE,yHAuCmB,aACrB3C,MAAO,OACP0C,WAAY,4CA/CW,CACvBC,UACE,2HAgDgB,aAClB3C,MAAO,OACP0C,WAAY,4CAhCQ,CACpBC,UACE,+EAiCa,aACfsB,OAAQ,cACRC,WAAY,OACZC,UAAW,oBACXvE,OAAQ,QAzEU,CAClBwE,WAAY,6CACZC,WAAY,MACZC,WAAY,UAyFA,CACZtE,MAAO,UACPiE,OAAQ,qBACRlE,eAAgB,OAChBsE,WAAY,MACZD,WAAW,4CCvHIG,GD0HF,2BACVR,GADU,IAEbvB,UAAW,YCvKQ,CACjBgC,SAAU,CACRR,SAAU,OACVpE,OAAQ,QAEV6E,WAAY,CACVhC,aAAc,kBAEhBiC,iBAAkB,CAChBjC,aAAc,kBAEhBkC,UAAW,CACThC,UACE,2EAEJiC,WAAY,CACV/E,MAAO,OACP0C,aAAc,YAEhBsC,WAAY,CACVhF,MAAO,OACPiF,oBAAqB,qBACrBC,qBAAsB,sBAExBC,cAAe,CACbnF,MAAO,OACPoF,uBAAwB,qBACxBC,wBAAyB,sBAE3BC,QAAS,CACPtF,MAAO,OACP4C,aAAc,sBAEhB2C,eAAgB,CACdvD,SAAU,WACVwD,IAAK,IACLC,MAAO,IACPC,OAAQ,IACRC,KAAM,IACN7B,QAAS,aCeA8B,EAnDA,yBACbC,QAAS,CAEPC,UAAW,UAEb5B,MAAM,2BACDA,GADA,IAEHxB,aAAc,OACd6B,WAAa,eACbpE,MAAM,UACNwC,UAAW,OACXV,UAAW,OACX/B,eAAgB,UAEf6F,GAdU,IAebC,SAAU,CACRzF,WAAY,OACZC,YAAa,QAEfyF,UAAW,CACT5B,WAAa,OACbE,WAAa,eACbpE,MAAM,WAER+F,WAAY,CACV/F,MAAO,WAETgG,YAAa,CACX5B,WAAY,gBAEZpE,MAAO,QAETiG,cAAe,CACb5E,eAAgB,qBAElB6E,QAAS,CACP1D,UAAW,IACX3C,MAAO,OACPsG,UAAW,OACXX,KAAM,IACNH,IAAK,IACLzF,OAAQ,OACR0E,WAAY,OACZxB,SAAU,OACV9C,MAAO,QAEToG,QAAS,CACPnC,OAAQ,SC3BN3E,EAAYC,YAAW4D,GAEd,SAASkD,IACtB,IAAM7F,EAAUlB,IACVgH,EAAe9C,IACnBhD,EAAQmE,UACRnE,EAAQkE,iBACRlE,EAAQgE,UAEV,OACE,yBAAKzD,UAAWP,EAAQkF,SACtB,kBAACzE,EAAA,EAAD,CAAYsF,QAAU,KAAKxF,UAAWP,EAAQuD,OAA9C,gBACA,6BACE,kBAACvC,EAAD,CAAeT,UAAWP,EAAQyF,eAChC,kBAAC/D,EAAD,CAAUsE,GAAI,EAAGC,GAAI,EAAGC,GAAI,GAC1B,kBAACtD,EAAD,CAAMC,OAAK,GACT,kBAACnB,EAAD,CAAUsE,GAAI,GAAIC,GAAI,GAAIC,GAAI,EAAG3F,UAAWP,EAAQqF,UACpD,yBAAKc,IAAKC,EAAQ,IAAwBC,IAAI,MAAM9F,UAAWuF,KAE/D,kBAACrF,EAAA,EAAD,CAAYF,UAAWP,EAAQsF,WAA/B,aACA,kBAACjC,EAAD,KACI,kBAAC5C,EAAA,EAAD,CAAYF,UAAWP,EAAQwF,aAA/B,4HAEA,6BAAS,uBAAGc,KAAK,yCAAR,gBAKjB,kBAAC5E,EAAD,CAAUsE,GAAI,EAAGC,GAAI,EAAGC,GAAI,GAC1B,kBAACtD,EAAD,CAAMC,OAAK,GACT,kBAACnB,EAAD,CAAUsE,GAAI,GAAIC,GAAI,GAAIC,GAAI,EAAG3F,UAAWP,EAAQqF,UACpD,yBAAKc,IAAKC,EAAQ,IAA6BC,IAAI,MAAM9F,UAAWuF,KAEpE,kBAACrF,EAAA,EAAD,CAAYF,UAAWP,EAAQsF,WAA/B,eACA,kBAACjC,EAAD,KACI,kBAAC5C,EAAA,EAAD,CAAYF,UAAWP,EAAQwF,aAA/B,iGACyF,6BACzF,uBAAGc,KAAK,0CAAR,gBAKR,kBAAC5E,EAAD,CAAUsE,GAAI,EAAGC,GAAI,EAAGC,GAAI,GAC1B,kBAACtD,EAAD,CAAMC,OAAK,GACT,kBAACnB,EAAD,CAAUsE,GAAI,GAAIC,GAAI,GAAIC,GAAI,EAAG3F,UAAWP,EAAQqF,UAClD,yBAAKc,IAAKC,EAAQ,IAAwBC,IAAI,MAAM9F,UAAWuF,KAEjE,kBAACrF,EAAA,EAAD,CAAYF,UAAWP,EAAQsF,WAA/B,UACA,kBAACjC,EAAD,KACI,kBAAC5C,EAAA,EAAD,CAAYF,UAAWP,EAAQwF,aAA/B,4GACyG,uBAAGc,KAAK,0CAAR,oB,qBChErHxH,EAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,QAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,QAEXgH,YAAa,CACTC,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVkH,qBAAsB,CAClB9C,WAAY,gBACZF,WAAW,QAEfiD,YAAa,GAGbC,UAAW,CACPvH,MAAO,MACPoH,cAAc,YA0BPI,EAtBC,WACZ,IAAM7G,EAAUlB,IAGhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACW,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,SAASf,QAAQ,KAAKxF,UAAWP,EAAQwG,aAA3D,uBAGA,kBAAC/F,EAAA,EAAD,CAAYqG,MAAM,SAASf,QAAQ,YAAYxF,UAAWP,EAAQ0G,sBAAlE,oeAKJ,yBAAKnG,UAAWP,EAAQ2G,YAAaR,IAAKY,IAASV,IAAI,QACvD,kBAAC,EAAD,QChDNvH,EAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,QAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,QAEXgH,YAAa,CACTC,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVwH,gBAAiB,CACbtD,WAAY,OACZ+C,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVkH,qBAAsB,CAClB9C,WAAY,iBAEhBqD,sBAAuB,CACnBrD,WAAY,gBACZT,QAAQ,QAEZyD,UAAW,CACPvH,MAAO,MACPoH,cAAc,YA6FPS,EAzFE,SAAC,GAAkB,EAAhBC,UAAiB,IAC3BnH,EAAUlB,IAGhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACW,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACxB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQwG,aAA/D,qBAGA,kBAAC/F,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,qYACkY,8BAGlY,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,SAASf,QAAQ,KAAKxF,UAAWP,EAAQgH,iBAA3D,YAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,gCACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,oDACiD,6BADjD,yDAEsD,6BAFtD,4BAGyB,6BAHzB,qDAIkD,6BAJlD,4DAKyD,6BALzD,+EAM4E,6BAN5E,IAMsF,8BAEtF,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,0BACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,2DACwD,6BADxD,8EAEuF,6BAFvF,oFAG6F,6BAH7F,oKAIiK,6BAJjK,qFAKkF,6BALlF,qIAMkI,6BANlI,sBAOmB,6BAAS,8BAE5B,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,2BACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,mFACgF,6BADhF,8BAE2B,6BAAS,8BAGpC,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,SAASf,QAAQ,KAAKxF,UAAWP,EAAQgH,iBAA3D,4BAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,uBACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,4CACyC,6BADzC,mDAEgD,6BAFhD,6EAGsF,8BAKtF,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,iBACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,KACE,uBAAGX,KAAK,2CAAR,gDADF,IACqG,6BADrG,4DAEqE,6BAFrE,sJAG+J,6BAH/J,uEAIoF,6BAAS,8BAG7F,kBAAC7F,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,mBACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,mDACgD,6BADhD,6EAE0E,6BAF1E,2DAGoE,6BAHpE,2CAIoD,6BAJpD,8DAKuE,6BALvE,gEAMyE,6BANzE,+EAOwF,6BAPxF,gFAQ6E,6BAR7E,iDAS8C,6BAT9C,yFAUsF,6BAAS,8BAG/F,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,KAAKxF,UAAWP,EAAQ0G,sBAAzD,qBACA,kBAACjG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,qrB,8JC1GNnI,GAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,QAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,QAEXoH,UAAW,CACPvH,MAAO,OAGXmH,YAAa,CACTC,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVwH,gBAAiB,CACbtD,WAAY,OACZ+C,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVkH,qBAAsB,CAClB9C,WAAY,iBAEhBqD,sBAAuB,CACnBrD,WAAY,gBACZT,QAAQ,QAEZwD,YAAa,OAoJFS,GA/IO,SAAC,GAAkB,EAAhBD,UAAiB,IAChCnH,EAAUlB,KAKhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACW,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WAGpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQwG,aAA/D,YAGA,kBAAC/F,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQ0G,sBAAhE,sVAEgI,+BAGpI,yBAAKnG,UAAWP,EAAQ2G,YAAaR,IAAKkB,KAAQhB,IAAI,QACtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,gBAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,usBAMA,kBAACxG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,YAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,kDAC+C,uBAAGX,KAAK,2CAAR,gDAD/C,ksCAOqJ,8BAIrJ,kBAAC7F,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,wCAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,8sBAGoO,+BAGxO,yBAAK1G,UAAWP,EAAQ2G,YAAaR,IAAKmB,KAASjB,IAAI,QACvD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,wwBAKS,+BAGb,kBAACxG,EAAA,EAAD,kCAGA,yBAAKF,UAAWP,EAAQ2G,YAAaR,IAAKoB,KAAiBlB,IAAI,QAE/D,kBAAC5F,EAAA,EAAD,qCAGA,yBAAKF,UAAWP,EAAQ2G,YAAaR,IAAKqB,KAAgBnB,IAAI,QAE9D,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,4KAEkE,+BAGtE,yBAAK1G,UAAWP,EAAQ2G,YAAaR,IAAKsB,KAAMpB,IAAI,QAEpD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,gTAGc,8BAEd,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,SAASf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAlE,UACQ,IADR,YACsB,IADtB,aACqC,IADrC,aACoD,IADpD,YACkE,IADlE,aACiF,IADjF,WAC8F,IAD9F,SACyG,IADzG,aACwH,IADxH,UACmI,8BAEnI,kBAACxG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,gtCAOgG,+BAGpG,yBAAK1G,UAAWP,EAAQ2G,YAAaR,IAAKuB,KAAMrB,IAAI,QACpD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,yQAE6G,+BAIjH,yBAAK1G,UAAWP,EAAQ2G,YAAaR,IAAKwB,KAAMtB,IAAI,QACpD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,wNAE+I,+BAGnJ,yBAAK1G,UAAWP,EAAQ2G,YAAaR,IAAKyB,KAAIvB,IAAI,QAElD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,mfAIoC,8BAGpC,kBAACxG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQwG,aAA/D,8BAGA,kBAAC/F,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,ixBAKiD,6BAAS,6BAAS,iC,4IC9K7EnI,GAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,QAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,QAEXoH,UAAW,CACPvH,MAAO,OAGXmH,YAAa,CACTC,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVwH,gBAAiB,CACbtD,WAAY,OACZ+C,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVkH,qBAAsB,CAClB9C,WAAY,iBAEhBqD,sBAAuB,CACnBrD,WAAY,gBACZT,QAAQ,QAEZwD,YAAa,GAGbkB,aAAc,CACVpB,cAAc,QAElBqB,aAAc,CACVpE,WAAW,YAwIJqE,GApIK,SAAC,GAAkB,EAAhBZ,UAAiB,IAC9BnH,EAAUlB,KAKhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACW,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WAGpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQwG,aAA/D,YAGA,kBAAC/F,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQ0G,sBAAhE,uUAE0L,6BAAS,+BAGvM,yBAAKnG,UAAWP,EAAQ2G,YAAaR,IAAKkB,KAAQhB,IAAI,QACtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACpB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,gBAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,k7CAiBA,kBAACxG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,YAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,kDAC+C,uBAAGX,KAAK,2CAAR,gDAD/C,osBACk1B,6BAAS,6BAD31B,inDAE8mD,+BAGtnD,kBAAC7F,EAAA,EAAD,yBACA,yBAAKF,UAAWP,EAAQ2G,YAAaR,IAAK6B,KAAQ3B,IAAI,QACtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WAChB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,gUAGkE,+BAG1E,kBAACxG,EAAA,EAAD,+BACA,yBAAKF,UAAWP,EAAQ6H,aAAc1B,IAAK8B,KAAS5B,IAAI,QACxD,kBAAC3F,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WAChB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,qwCAEA,6BACA,6BAHA,wuBAKA,+BAIR,kBAACvG,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,wCAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,kbAIR,kBAACxG,EAAA,EAAD,sBACA,yBAAKF,UAAWP,EAAQ8H,aAAc3B,IAAK+B,KAAO7B,IAAI,QACtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,2/BAIR,kBAACxG,EAAA,EAAD,KAAY,6BAAZ,oBACA,yBAAKF,UAAWP,EAAQ8H,aAAc3B,IAAKgC,KAAO9B,IAAI,QAEtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,gTAKR,kBAACxG,EAAA,EAAD,KAAY,6BAAZ,qBACA,yBAAKF,UAAWP,EAAQ8H,aAAc3B,IAAKiC,KAAO/B,IAAI,QAEtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,ygBAEA,+BAIR,kBAACxG,EAAA,EAAD,4BACA,yBAAKF,UAAWP,EAAQ8H,aAAc3B,IAAKkC,KAAShC,IAAI,QACxD,kBAAC5F,EAAA,EAAD,KAAY,6BAAZ,qBACA,yBAAKF,UAAWP,EAAQ8H,aAAc3B,IAAKmC,KAAOjC,IAAI,QAEtD,kBAAC3F,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,sqBAEA,+BAIR,kBAACvG,EAAA,EAAD,CAAKH,UAAaP,EAAQ4G,WAClB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQgH,iBAA/D,8BAGA,kBAACvG,EAAA,EAAD,CAAYqG,MAAM,OAAOf,QAAQ,YAAYxF,UAAWP,EAAQiH,uBAAhE,uvBACovB,6BAAS,6BAAS,iCClLhxBnI,GAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,OAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,YAoBA+I,GAhBM,SAAC,GAAkB,EAAhBpB,UAAiB,IAC/BnH,EAAUlB,KAKhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACU,EAAA,EAAD,sB,oBCpBN3B,GAAYC,aAAW,SAACC,GAAD,MAAY,CACrCuH,QAAS,CACL5F,QAAS,OACTzB,WAAY,SACZ0B,cAAc,SACd8C,WAAW,MAEfpE,KAAM,CACFC,eAAgB,OAChBC,MAAO,QAEXgH,YAAa,CACTC,cAAc,OACdlH,eAAgB,OAChBC,MAAM,WAGVgJ,gBAAiB,CACb5E,WAAY,iBAEhBgD,UAAW,CACPvH,MAAO,WAuBAoJ,GAnBI,SAAC,GAAkB,EAAhBtB,UAAiB,IAC7BnH,EAAUlB,KAKhB,OACI,yBAAKyB,UAAWP,EAAQuG,SACpB,kBAACxG,EAAD,MACA,kBAACW,EAAA,EAAD,CAAKH,UAAWP,EAAQ4G,WACxB,kBAACnG,EAAA,EAAD,CAAYqG,MAAQ,SAASf,QAAU,KAAKxF,UAAWP,EAAQwG,aAA/D,eAIA,yBAAKjG,UAAWP,EAAQ2G,YAAaR,IAAKuC,KAAKrC,IAAI,UCrCzDrH,I,MAAQ2J,YAAe,CAC3BC,QAAS,CACLC,QAAS,CAELC,KAAM,WAIVC,UAAW,CACPD,KAAM,UAENE,aAAc,WAIlBC,kBAAmB,EAInBC,YAAa,IAEjBC,WAAY,CACRvF,WAAY,CACR,gBAYAwF,KAAK,SAsBAC,G,uKAhBT,OACI,8BACI,kBAACC,EAAA,EAAD,CAAetK,MAAOA,IAClB,kBAAC,IAAD,KACI,kBAAC,IAAD,CAAOuK,OAAK,EAACC,KAAI,IAAOC,UAAW5C,IACnC,kBAAC,IAAD,CAAO0C,OAAK,EAACC,KAAI,YAAeE,OAAQ,kBAAM,kBAAC,EAAD,SAC9C,kBAAC,IAAD,CAAOH,OAAK,EAACC,KAAI,iBAAoBE,OAAQ,kBAAM,kBAAC,GAAD,SACnD,kBAAC,IAAD,CAAOH,OAAK,EAACC,KAAI,eAAkBE,OAAQ,kBAAM,kBAAC,GAAD,SACjD,kBAAC,IAAD,CAAOH,OAAK,EAACC,KAAI,gBAAmBE,OAAQ,kBAAM,kBAAC,GAAD,SAClD,kBAAC,IAAD,CAAOH,OAAK,EAACC,KAAI,cAAiBE,OAAQ,kBAAM,kBAAC,GAAD,gB,GAXpD/K,IAAMgL,WC3CxBC,IAASF,OACL,kBAAC,IAAD,CAAYG,SAAUC,KAClB,kBAAC,GAAD,OAEJC,SAASC,eAAe,W","file":"static/js/main.42994f16.chunk.js","sourcesContent":["module.exports = __webpack_public_path__ + \"static/media/teaser.03c69802.png\";","module.exports = \"data:image/png;base64,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\"","module.exports = __webpack_public_path__ + \"static/media/32x32.e788ac26.png\";","module.exports = __webpack_public_path__ + \"static/media/digitLengthDist.cc510657.png\";","module.exports = __webpack_public_path__ + \"static/media/individualDigitDist.118b3265.png\";","module.exports = __webpack_public_path__ + \"static/media/gray.1899d1d8.png\";","module.exports = __webpack_public_path__ + \"static/media/conv.c651a779.png\";","module.exports = __webpack_public_path__ + \"static/media/max-pooling.8ebf998d.png\";","module.exports = __webpack_public_path__ + \"static/media/fully-connected.3b9a9ccc.png\";","module.exports = __webpack_public_path__ + \"static/media/oneHot.3899e148.png\";","module.exports = __webpack_public_path__ + \"static/media/softmax.b79b7933.png\";","module.exports = __webpack_public_path__ + \"static/media/model.d9a4b931.png\";","module.exports = __webpack_public_path__ + \"static/media/train.56562c7b.png\";","module.exports = __webpack_public_path__ + \"static/media/epoch.5bba88e1.png\";","module.exports = __webpack_public_path__ + \"static/media/correct.69f6d9f3.png\";","module.exports = __webpack_public_path__ + \"static/media/wrong.7f3224e5.png\";","module.exports = __webpack_public_path__ + \"static/media/references.cc2d85a1.png\";","module.exports = __webpack_public_path__ + \"static/media/bruce.c497048c.png\";","module.exports = __webpack_public_path__ + \"static/media/tiantongli.07629d40.png\";","module.exports = __webpack_public_path__ + \"static/media/yiqin.2892f654.png\";","import React from 'react';\nimport PropTypes from 'prop-types';\nimport AppBar from '@material-ui/core/AppBar';\nimport Toolbar from '@material-ui/core/Toolbar';\nimport CssBaseline from '@material-ui/core/CssBaseline';\nimport useScrollTrigger from '@material-ui/core/useScrollTrigger';\nimport { Typography } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Link } from 'react-router-dom';\nimport Button from '@material-ui/core/Button';\nimport Box from '@material-ui/core/Box';\n\n\nfunction ElevationScroll(props) {\n  const { children, window } = props;\n  // Note that you normally won't need to set the window ref as useScrollTrigger\n  // will default to window.\n  // This is only being set here because the demo is in an iframe.\n  const trigger = useScrollTrigger({\n    disableHysteresis: true,\n    threshold: 0,\n    target: window ? window() : undefined,\n  });\n\n  return React.cloneElement(children, {\n    elevation: trigger ? 4 : 0,\n  });\n}\n\nElevationScroll.propTypes = {\n  children: PropTypes.element.isRequired,\n  /**\n   * Injected by the documentation to work in an iframe.\n   * You won't need it on your project.\n   */\n  window: PropTypes.func,\n};\n\nconst useStyles = makeStyles((theme) => ({\n  fab: {\n    alignItems: 'center',\n  },\n  image: {\n    height: 'auto',\n    width: '4%',\n  },\n  link: {\n    textDecoration: 'none',\n    color: '#000',\n  },\n  button: {\n    textTransform: 'none',\n    color: 'primary',\n  },\n  rightJustify: {\n    marginLeft: \"auto\",\n    marginRight: '0%',\n  },\n  leftJustify: {\n    marginRight: \"auto\",\n    marginLeft: '0%',\n  },\n}));\n\nexport default function Header(props) {\n  const classes = useStyles();\n  return (\n    <React.Fragment>\n      <CssBaseline />\n      <ElevationScroll {...props}>\n        <AppBar color={'secondary'}>\n          <Toolbar>\n            <section classeName={classes.leftJustify}>\n                <Link to=\"/\" className={classes.link} >\n                  <Button className={classes.button}>\n                  <Typography color = 'primary'>CS4476 Project: Scene Text Detection</Typography>\n                  </Button>\n                </Link>\n            </section>\n            <section className = {classes.rightJustify}>\n              <Box display=\"flex\" flexDirection=\"row\" justifyContent='space-between'>\n              <Box p = {1}>\n                <Link to=\"/proposal\" className={classes.link} >\n                  <Button className={classes.button}>\n                    <Typography>Proposal</Typography>\n                  </Button>\n                </Link>\n              </Box>\n              <Box p = {1}>\n                <Link to=\"/midtermUpdate\" className={classes.link} >\n                  <Button className={classes.button}>\n                    <Typography>Midterm Update</Typography>\n                  </Button>\n                </Link>\n              </Box>\n              <Box p = {1}>\n                <Link to=\"/finalUpdate\" className={classes.link} >\n                  <Button className={classes.button}>\n                    <Typography>Final Update</Typography>\n                  </Button>\n                </Link>\n              </Box>\n              <Box p = {1}>\n                <Link to=\"/projectVideo\" className={classes.link} >\n                  <Button className={classes.button}>\n                    <Typography>Project Video</Typography>\n                  </Button>\n                </Link>\n              </Box>\n              <Box p = {1}>\n                <Link to=\"/references\" className={classes.link} >\n                  <Button className={classes.button}>\n                    <Typography>References</Typography>\n                  </Button>\n                </Link>\n              </Box>\n              </Box>\n            </section>\n          </Toolbar>\n        </AppBar>\n      </ElevationScroll>\n      <Toolbar />\n    </React.Fragment>\n  );\n}\n\n\n","import React from \"react\";\n// nodejs library to set properties for components\nimport PropTypes from \"prop-types\";\n\n// @material-ui/core components\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport Grid from \"@material-ui/core/Grid\";\n\nconst styles = {\n  grid: {\n    marginRight: \"-15px\",\n    marginLeft: \"-15px\",\n    width: \"auto\"\n  }\n};\n\nconst useStyles = makeStyles(styles);\n\nexport default function GridContainer(props) {\n  const classes = useStyles();\n  const { children, className, ...rest } = props;\n  return (\n    <Grid container {...rest} className={classes.grid + \" \" + className}>\n      {children}\n    </Grid>\n  );\n}\n\nGridContainer.defaultProps = {\n  className: \"\"\n};\n\nGridContainer.propTypes = {\n  children: PropTypes.node,\n  className: PropTypes.string\n};","import React from \"react\";\n// nodejs library to set properties for components\nimport PropTypes from \"prop-types\";\n// @material-ui/core components\nimport { makeStyles } from \"@material-ui/core/styles\";\nimport Grid from \"@material-ui/core/Grid\";\n\nconst styles = {\n  grid: {\n    position: \"relative\",\n    width: \"100%\",\n    minHeight: \"1px\",\n    paddingRight: \"15px\",\n    paddingLeft: \"15px\",\n    flexBasis: \"auto\"\n  }\n};\n\nconst useStyles = makeStyles(styles);\n\nexport default function GridItem(props) {\n  const classes = useStyles();\n  const { children, className, ...rest } = props;\n  return (\n    <Grid item {...rest} className={classes.grid + \" \" + className}>\n      {children}\n    </Grid>\n  );\n}\n\nGridItem.defaultProps = {\n  className: \"\"\n};\n\nGridItem.propTypes = {\n  children: PropTypes.node,\n  className: PropTypes.string\n};\n","const cardStyle = {\n    card: {\n      border: \"0\",\n      marginBottom: \"30px\",\n      marginTop: \"30px\",\n      borderRadius: \"6px\",\n      color: \"rgba(0, 0, 0, 0.87)\",\n      background: \"#fff\",\n      width: \"100%\",\n      boxShadow:\n        \"0 2px 2px 0 rgba(0, 0, 0, 0.14), 0 3px 1px -2px rgba(0, 0, 0, 0.2), 0 1px 5px 0 rgba(0, 0, 0, 0.12)\",\n      position: \"relative\",\n      display: \"flex\",\n      flexDirection: \"column\",\n      minWidth: \"0\",\n      wordWrap: \"break-word\",\n      fontSize: \".875rem\",\n      transition: \"all 300ms linear\"\n    },\n    cardPlain: {\n      background: \"transparent\",\n      boxShadow: \"none\"\n    },\n    cardCarousel: {\n      overflow: \"hidden\"\n    }\n  };\n  \n  export default cardStyle;\n  ","import React from \"react\";\n// nodejs library that concatenates classes\nimport classNames from \"classnames\";\n// nodejs library to set properties for components\nimport PropTypes from \"prop-types\";\n// @material-ui/core components\nimport { makeStyles } from \"@material-ui/core/styles\";\n// @material-ui/icons\n\n// core components\nimport styles from \"./cardStyle.js\";\n\nconst useStyles = makeStyles(styles);\n\nexport default function Card(props) {\n  const classes = useStyles();\n  const { className, children, plain, carousel, ...rest } = props;\n  const cardClasses = classNames({\n    [classes.card]: true,\n    [classes.cardPlain]: plain,\n    [classes.cardCarousel]: carousel,\n    [className]: className !== undefined\n  });\n  return (\n    <div className={cardClasses} {...rest}>\n      {children}\n    </div>\n  );\n}\n\nCard.propTypes = {\n  className: PropTypes.string,\n  plain: PropTypes.bool,\n  carousel: PropTypes.bool,\n  children: PropTypes.node\n};\n","const cardBodyStyle = {\n    cardBody: {\n      padding: \"0.9375rem 1.875rem\",\n      flex: \"1 1 auto\"\n    }\n  };\n  \n  export default cardBodyStyle;\n  ","import React from \"react\";\n// nodejs library that concatenates classes\nimport classNames from \"classnames\";\n// nodejs library to set properties for components\nimport PropTypes from \"prop-types\";\n// @material-ui/core components\nimport { makeStyles } from \"@material-ui/core/styles\";\n// @material-ui/icons\n\n// core components\nimport styles from \"./cardBodyStyle.js\";\n\nconst useStyles = makeStyles(styles);\n\nexport default function CardBody(props) {\n  const classes = useStyles();\n  const { className, children, ...rest } = props;\n  const cardBodyClasses = classNames({\n    [classes.cardBody]: true,\n    [className]: className !== undefined\n  });\n  return (\n    <div className={cardBodyClasses} {...rest}>\n      {children}\n    </div>\n  );\n}\n\nCardBody.propTypes = {\n  className: PropTypes.string,\n  children: PropTypes.node\n};\n","/*!\n\n =========================================================\n * Material Kit React - v1.9.0 based on Material Kit - v2.0.2\n =========================================================\n\n * Product Page: https://www.creative-tim.com/product/material-kit-react\n * Copyright 2020 Creative Tim (https://www.creative-tim.com)\n * Licensed under MIT (https://github.com/creativetimofficial/material-kit-react/blob/master/LICENSE.md)\n\n =========================================================\n\n * The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\n */\n\n// ##############################\n// // // Variables - Styles that are used on more than one component\n// #############################\n\nconst drawerWidth = 260;\n\nconst transition = {\n  transition: \"all 0.33s cubic-bezier(0.685, 0.0473, 0.346, 1)\"\n};\n\nconst containerFluid = {\n  paddingRight: \"15px\",\n  paddingLeft: \"15px\",\n  marginRight: \"auto\",\n  marginLeft: \"auto\",\n  width: \"100%\"\n};\nconst container = {\n  ...containerFluid,\n  \"@media (min-width: 576px)\": {\n    maxWidth: \"540px\"\n  },\n  \"@media (min-width: 768px)\": {\n    maxWidth: \"720px\"\n  },\n  \"@media (min-width: 992px)\": {\n    maxWidth: \"960px\"\n  },\n  \"@media (min-width: 1200px)\": {\n    maxWidth: \"1140px\"\n  }\n};\n\nconst boxShadow = {\n  boxShadow:\n    \"0 10px 30px -12px rgba(0, 0, 0, 0.42), 0 4px 25px 0px rgba(0, 0, 0, 0.12), 0 8px 10px -5px rgba(0, 0, 0, 0.2)\"\n};\n\nconst card = {\n  display: \"inline-block\",\n  position: \"relative\",\n  width: \"100%\",\n  margin: \"25px 0\",\n  boxShadow: \"0 1px 4px 0 rgba(0, 0, 0, 0.14)\",\n  borderRadius: \"3px\",\n  color: \"rgba(0, 0, 0, 0.87)\",\n  background: \"#fff\"\n};\n\nconst defaultFont = {\n  fontFamily: '\"Roboto\", \"Helvetica\", \"Arial\", sans-serif',\n  fontWeight: \"300\",\n  lineHeight: \"1.5em\"\n};\n\nconst primaryColor = \"#9c27b0\";\nconst warningColor = \"#ff9800\";\nconst dangerColor = \"#f44336\";\nconst successColor = \"#4caf50\";\nconst infoColor = \"#00acc1\";\nconst roseColor = \"#e91e63\";\nconst grayColor = \"#999999\";\n\nconst primaryBoxShadow = {\n  boxShadow:\n    \"0 12px 20px -10px rgba(156, 39, 176, 0.28), 0 4px 20px 0px rgba(0, 0, 0, 0.12), 0 7px 8px -5px rgba(156, 39, 176, 0.2)\"\n};\nconst infoBoxShadow = {\n  boxShadow:\n    \"0 12px 20px -10px rgba(0, 188, 212, 0.28), 0 4px 20px 0px rgba(0, 0, 0, 0.12), 0 7px 8px -5px rgba(0, 188, 212, 0.2)\"\n};\nconst successBoxShadow = {\n  boxShadow:\n    \"0 12px 20px -10px rgba(76, 175, 80, 0.28), 0 4px 20px 0px rgba(0, 0, 0, 0.12), 0 7px 8px -5px rgba(76, 175, 80, 0.2)\"\n};\nconst warningBoxShadow = {\n  boxShadow:\n    \"0 12px 20px -10px rgba(255, 152, 0, 0.28), 0 4px 20px 0px rgba(0, 0, 0, 0.12), 0 7px 8px -5px rgba(255, 152, 0, 0.2)\"\n};\nconst dangerBoxShadow = {\n  boxShadow:\n    \"0 12px 20px -10px rgba(244, 67, 54, 0.28), 0 4px 20px 0px rgba(0, 0, 0, 0.12), 0 7px 8px -5px rgba(244, 67, 54, 0.2)\"\n};\nconst roseBoxShadow = {\n  boxShadow:\n    \"0 4px 20px 0px rgba(0, 0, 0, 0.14), 0 7px 10px -5px rgba(233, 30, 99, 0.4)\"\n};\n\nconst warningCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #ffa726, #fb8c00)\",\n  ...warningBoxShadow\n};\nconst successCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #66bb6a, #43a047)\",\n  ...successBoxShadow\n};\nconst dangerCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #ef5350, #e53935)\",\n  ...dangerBoxShadow\n};\nconst infoCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #26c6da, #00acc1)\",\n  ...infoBoxShadow\n};\nconst primaryCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #ab47bc, #8e24aa)\",\n  ...primaryBoxShadow\n};\nconst roseCardHeader = {\n  color: \"#fff\",\n  background: \"linear-gradient(60deg, #ec407a, #d81b60)\",\n  ...roseBoxShadow\n};\nconst cardActions = {\n  margin: \"0 20px 10px\",\n  paddingTop: \"10px\",\n  borderTop: \"1px solid #eeeeee\",\n  height: \"auto\",\n  ...defaultFont\n};\n\nconst cardHeader = {\n  margin: \"-30px 15px 0\",\n  borderRadius: \"3px\",\n  padding: \"15px\"\n};\n\nconst defaultBoxShadow = {\n  border: \"0\",\n  borderRadius: \"3px\",\n  boxShadow:\n    \"0 10px 20px -12px rgba(0, 0, 0, 0.42), 0 3px 20px 0px rgba(0, 0, 0, 0.12), 0 8px 10px -5px rgba(0, 0, 0, 0.2)\",\n  padding: \"10px 0\",\n  transition: \"all 150ms ease 0s\"\n};\n\nconst title = {\n  color: \"#3C4858\",\n  margin: \"1.75rem 0 0.875rem\",\n  textDecoration: \"none\",\n  fontWeight: \"700\",\n  fontFamily: `\"Roboto Slab\", \"Times New Roman\", serif`\n};\n\nconst cardTitle = {\n  ...title,\n  marginTop: \".625rem\"\n};\n\nconst cardLink = {\n  \"& + $cardLink\": {\n    marginLeft: \"1.25rem\"\n  }\n};\n\nconst cardSubtitle = {\n  marginBottom: \"0\",\n  marginTop: \"-.375rem\"\n};\n\nexport {\n  //variables\n  drawerWidth,\n  transition,\n  container,\n  containerFluid,\n  boxShadow,\n  card,\n  defaultFont,\n  primaryColor,\n  warningColor,\n  dangerColor,\n  successColor,\n  infoColor,\n  roseColor,\n  grayColor,\n  primaryBoxShadow,\n  infoBoxShadow,\n  successBoxShadow,\n  warningBoxShadow,\n  dangerBoxShadow,\n  roseBoxShadow,\n  warningCardHeader,\n  successCardHeader,\n  dangerCardHeader,\n  infoCardHeader,\n  primaryCardHeader,\n  roseCardHeader,\n  cardActions,\n  cardHeader,\n  defaultBoxShadow,\n  title,\n  cardTitle,\n  cardLink,\n  cardSubtitle\n};\n","const imagesStyles = {\n    imgFluid: {\n      maxWidth: \"100%\",\n      height: \"auto\"\n    },\n    imgRounded: {\n      borderRadius: \"6px !important\"\n    },\n    imgRoundedCircle: {\n      borderRadius: \"50% !important\"\n    },\n    imgRaised: {\n      boxShadow:\n        \"0 5px 15px -8px rgba(0, 0, 0, 0.24), 0 8px 10px -5px rgba(0, 0, 0, 0.2)\"\n    },\n    imgGallery: {\n      width: \"100%\",\n      marginBottom: \"2.142rem\"\n    },\n    imgCardTop: {\n      width: \"100%\",\n      borderTopLeftRadius: \"calc(.25rem - 1px)\",\n      borderTopRightRadius: \"calc(.25rem - 1px)\"\n    },\n    imgCardBottom: {\n      width: \"100%\",\n      borderBottomLeftRadius: \"calc(.25rem - 1px)\",\n      borderBottomRightRadius: \"calc(.25rem - 1px)\"\n    },\n    imgCard: {\n      width: \"100%\",\n      borderRadius: \"calc(.25rem - 1px)\"\n    },\n    imgCardOverlay: {\n      position: \"absolute\",\n      top: \"0\",\n      right: \"0\",\n      bottom: \"0\",\n      left: \"0\",\n      padding: \"1.25rem\"\n    }\n  };\n  \n  export default imagesStyles;\n  ","import { title } from \"../Card/material-kit-react.js\";\nimport imagesStyle from \"./imageStyles.js\";\n\nconst teamStyle = {\n  section: {\n    //padding: \"70px 0\",\n    textAlign: \"center\"\n  },\n  title: {\n    ...title,\n    marginBottom: \"1rem\",\n    fontFamily : '\"Space Mono\"',\n    color:'#212F3C',\n    marginTop: \"30px\",\n    minHeight: \"32px\",\n    textDecoration: \"none\"\n  },\n  ...imagesStyle,\n  itemGrid: {\n    marginLeft: \"auto\",\n    marginRight: \"auto\"\n  },\n  cardTitle: {\n    paddingTop : '10px',\n    fontFamily : '\"Space Mono\"',\n    color:'#212F3C',\n  },\n  smallTitle: {\n    color: \"#6c757d\"\n  },\n  description: {\n    fontFamily: '-apple-system',\n    //fontFamily : '\"Space Mono\"',\n    color: \"#999\"\n  },\n  justifyCenter: {\n    justifyContent: \"center !important\"\n  },\n  socials: {\n    marginTop: \"0\",\n    width: \"100%\",\n    transform: \"none\",\n    left: \"0\",\n    top: \"0\",\n    height: \"100%\",\n    lineHeight: \"41px\",\n    fontSize: \"20px\",\n    color: \"#999\"\n  },\n  margin5: {\n    margin: \"5px\"\n  }\n};\n\nexport default teamStyle;\n","import React from \"react\";\n// nodejs library that concatenates classes\nimport classNames from \"classnames\";\n// @material-ui/core components\nimport { makeStyles } from \"@material-ui/core/styles\";\n\n// @material-ui/icons\n\n// core components\nimport GridContainer from \"../Grid/GridContainer.js\";\nimport GridItem from \"../Grid/GridItem.js\";\nimport Card from \"../Card/Card.js\";\nimport CardBody from \"../Card/CardBody.js\";\n//import CardFooter from \"../Card/CardFooter.js\";\n\n//import Button from \"../CustomButtons/Button.js\";\nimport styles from \"./teamStyles.js\";\n\n//import team1 from \"../../img/bruce.png\";\n//import team2 from \"../../img/tiantongli.png\";\n//import team3 from \"../../img/yiqin.png\";\nimport { Typography } from \"@material-ui/core\";\n\nconst useStyles = makeStyles(styles);\n\nexport default function Description() {\n  const classes = useStyles();\n  const imageClasses = classNames(\n    classes.imgRaised,\n    classes.imgRoundedCircle,\n    classes.imgFluid\n  );\n  return (\n    <div className={classes.section}>\n      <Typography variant = 'h5' className={classes.title}>Team Members</Typography>\n      <div>\n        <GridContainer className={classes.justifyCenter}>\n          <GridItem xs={8} sm={8} md={3}>\n            <Card plain>\n              <GridItem xs={12} sm={12} md={5} className={classes.itemGrid}>\n              <img src={require(\"../../img/bruce.png\")} alt=\"...\" className={imageClasses}></img>\n              </GridItem>\n              <Typography className={classes.cardTitle}>Bruce Qin</Typography>\n              <CardBody>\n                  <Typography className={classes.description}>\n                    I am an undergraduate Electrical Engineering student at Georgia Institute of Technology with a minor in Computer Science. \n                  <br></br><a href=\"https://www.linkedin.com/in/bruce-qin\">LinkedIn</a>\n                  </Typography>\n              </CardBody>\n            </Card>\n          </GridItem>\n          <GridItem xs={8} sm={8} md={3}>\n            <Card plain>\n              <GridItem xs={12} sm={12} md={5} className={classes.itemGrid}>\n              <img src={require(\"../../img/tiantongli.png\")} alt=\"...\" className={imageClasses}></img>\n              </GridItem>\n              <Typography className={classes.cardTitle}>Tiantong Li</Typography>\n              <CardBody>\n                  <Typography className={classes.description}>\n                  I’m an undergraduate in Computer Science, focusing on Artificial Intelligence and Media. <br></br>\n                  <a href=\"https://www.linkedin.com/in/tiantongli\">LinkedIn</a>\n                  </Typography>\n              </CardBody>\n            </Card>\n          </GridItem>\n          <GridItem xs={8} sm={8} md={3}>\n            <Card plain>\n              <GridItem xs={12} sm={12} md={5} className={classes.itemGrid}>\n                <img src={require(\"../../img/yiqin.png\")} alt=\"...\" className={imageClasses}></img>\n              </GridItem>\n              <Typography className={classes.cardTitle}>Yi Qin</Typography>\n              <CardBody>\n                  <Typography className={classes.description}>\n                  I am an undergraduate Computer Science student at Georgia Institute of Technology. Look at my profile on <a href=\"https://www.linkedin.com/in/yiqin1227/\">LinkedIn.</a>\n                  </Typography>\n              </CardBody>\n            </Card>\n          </GridItem>\n        </GridContainer>\n        </div>\n    </div>\n  );\n}\n","import React from 'react';\n\nimport { Typography, Box } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header, TeamDescription } from '../../components';\n//import { Link } from 'react-router-dom';\n//import ButtonBase from '@material-ui/core/ButtonBase';\nimport mainFig from \"../../img/digits.png\";\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'20px',\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n    titleFormat: {\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    titleParagraphFormat: {\n        fontFamily: '-apple-system',\n        paddingTop:'20px',\n    },\n    imageFormat: {\n        //paddingBottom:'10px',\n    },\n    boxFormat: {\n        width: '80%',\n        paddingBottom:'30px',\n    }\n}));\n\nconst Landing = () => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Box className={classes.boxFormat}>\n                <Typography align='center' variant='h3' className={classes.titleFormat}>\n                    SVHN Digit Detector\n                </Typography>\n                <Typography align='center' variant='subtitle1' className={classes.titleParagraphFormat}>\n                Detecting and recognizing text in natural scene images and optical character recognition is a challenging task computer scientists have been working on and improving for a long time. We want to work with the Street View House Number (SVHN) dataset to create a digit detector program.\n                With the given input of an image taken from a camera or extracted from Google street view, our detector will extract the house numbers and display the predicted output based on the trained model.\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={mainFig} alt=\"...\"></img>\n            <TeamDescription></TeamDescription>\n        </div>\n    )\n}\n\nexport default Landing;","import React from 'react';\n\nimport { Typography, Box } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header } from '../../components';\n//import { Link } from 'react-router-dom';\n\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'20px'\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n    titleFormat: {\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    lateTitleFormat: {\n        paddingTop: '20px',\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    titleParagraphFormat: {\n        fontFamily: '-apple-system',\n    },\n    titleParagraphFormat2: {\n        fontFamily: '-apple-system',\n        padding:'15px',\n    },\n    boxFormat: {\n        width: '70%',\n        paddingBottom:'30px',\n    },\n}));\n\nconst Proposal = ({ tagChange }) => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Box className={classes.boxFormat}>\n            <Typography align = 'center' variant = 'h4' className={classes.titleFormat}>\n                Problem Statement\n            </Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            When someone uses our system, they are expected to input images of house numbers displayed on streets. These images should be taken from a camera, or extracted from Google street view, with random background and diverse colors, but have the house numbers locating in the middle. The desired output is the same image with detected house numbers labeled besides the actual house numbers. <br></br>\n            </Typography>\n\n            <Typography align='center' variant='h4' className={classes.lateTitleFormat}>\n                Approach\n            </Typography>\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Image Processing Techniques:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - Convert the input image into a grayscale image <br></br>\n            - Adjust lighting into desired condition in the image <br></br>\n            - Denoise from the image <br></br>\n            - Use the canny edge detector to detect the edges <br></br>\n            - Normalising intensity of data through mean subtraction <br></br>\n            - Experiment with different types of contrast normalisation (global, local) <br></br> <br></br>\n            </Typography>\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}> Scene Text Detection:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - The dataset comes in two different formats from SVHN: <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Images with character level bounding boxes <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - 32-by-32 images centered around single character <br></br>\n            - For images that do not have a bounding box, use YOLO to find the text box with a single neural network to predict bounding boxes and label the bounding boxes  <br></br>\n            - After the bounding boxes are determined, crop the image into individual digits. <br></br>\n            - Use findCountours() function in OpenCV library to detect separate portion of the image with continuous pixels of the same color <br></br>\n            - Save each number <br></br><br></br>\n            </Typography>\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Scene Text Recognition:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - Build a convolutional neural network architecture using TensorFlow from Keras <br></br>\n            - Pass in training dataset <br></br><br></br>\n            </Typography>\n\n            <Typography align='center' variant='h4' className={classes.lateTitleFormat}>\n                Experiments and Results:\n            </Typography>\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Experimental Setup:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - Download and load the testing data set <br></br>\n            - Have the followings downloaded and installed: <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Python3, Numpy, OpenCV, Keras, TensorFlow <br></br>\n\n            </Typography>\n\n\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Dataset Used:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - <a href=\"http://ufldl.stanford.edu/housenumbers/\">The Street View House Numbers (SVHN) Dataset</a> <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Real-world image dataset <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Over 600,000 digit images (73,257 digits for training, 26,032 digits for testing, 531,131 additional less difficult<br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; samples for extra training) <br></br><br></br>\n            </Typography>\n\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Implementation:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            - Retrieve an image from the testing image pool <br></br>\n            - Pre-process the image using the same approach as our training approach: <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Converting to Grayscale <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Denoise <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Apply canny edge detectors <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - Find contours of the numbers <br></br>\n            &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - May need to normalise the intensity of data <br></br>\n            - Use our training approach to make predictions for each letter respectively <br></br>\n            - Combine the predicted letters as the answer <br></br>\n            - Compare the predicted answer with the actual answer given by the testing image pool <br></br><br></br>\n            </Typography>\n\n            <Typography align='left' variant='h5' className={classes.titleParagraphFormat}>Expected Results:</Typography>\n            <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n            Given the images from the testing image pool as input for the above implementation, we believe that there is an intensive amount of data inside the pool, thus the dataset should be enough to test the system. \n            We hope to measure the precision of our predicted answer compare it with the actual answer and reach a success rate of at least 80%. In order to determien the rate of success,  we will be using the number of correct detection divided by the total number of letter input. \n            Some possible error we foresee with our mode is the effect of natural lighting conditions and other image precision factors, it is uncertain if the output for blurry/low precision images is desirable enough.\n            </Typography>\n\n            </Box>\n        </div>\n    )\n}\n\nexport default Proposal;","import React from 'react';\n\nimport { Typography, Box } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header } from '../../components';\n//import { Link } from 'react-router-dom';\n\n\nimport teaser from \"../../img/teaser.png\";\nimport cropped from \"../../img/32x32.png\";\nimport digitLengthDist from \"../../img/digitLengthDist.png\";\nimport individualDist from \"../../img/individualDigitDist.png\";\nimport gray from \"../../img/gray.png\";\nimport conv from \"../../img/conv.png\";\nimport pool from \"../../img/max-pooling.png\";\nimport fc from \"../../img/fully-connected.png\";\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'20px'\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n    boxFormat: {\n        width: '70%',\n        //paddingBottom:'20px',\n    },\n    titleFormat: {\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    lateTitleFormat: {\n        paddingTop: '20px',\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    titleParagraphFormat: {\n        fontFamily: '-apple-system',\n    },\n    titleParagraphFormat2: {\n        fontFamily: '-apple-system',\n        padding:'10px',\n    },\n    imageFormat: {\n        //paddingBottom:'10px',\n    },\n}));\n\nconst MidtermUpdate = ({ tagChange }) => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Box className={classes.boxFormat}>\n\n\n                <Typography align = 'center' variant = 'h4' className={classes.titleFormat}>\n                    Abstract\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat}>\n                The goal of our project is to train a convolutional neural network to detect the digits of a house number displayed on the streets. This is a basic image recognition that can be useful in many different fields.\n                For the first update, we were able to preprocess all the images and begin setting up the different layers of our neural network.<br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={teaser} alt=\"...\"></img>\n            <Box className={classes.boxFormat}>\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Introduction\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                As shown in the image above, our project targets images of house number displayed on the streets, we hope to achieve reasonable results given a variety of resolution of the images. Digit recognition, is becoming increasingly \n                important in various domains as technology advances. Whether it is a mapping company needing to match images of house numbers to their geolocations, or a robot trying to locate itself through room numbers/house numbers, SVHN serves as a good\n                basic dataset to dive into the world of image recognition. We wanted to implement our project from scratch to understand how to preprocess the dataset as well as gain a deeper understanding of how to set up and train our own neural network.\n                </Typography>\n\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Approach\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                The first step was to preprocess the data from <a href=\"http://ufldl.stanford.edu/housenumbers/\">The Street View House Numbers (SVHN) Dataset</a>. We first focused on the first part of the dataset, \n                where colored house-number images are given where the bounding box for each digit is given in a .mat file. \n                The general steps we took to preprocess the image dataset was to: limit the maximum number of digit to 5 (there is one image that has 6 digits in the picture), make a new bounding box given the min and max\n                values of the x and y values for all bounding boxes of all digits, expand the bounding box in each direction by 30% to ensure coverage of all digit details, then convert the image to grayscale. These preprocessing techniques\n                are written with concepts we learned from class as we are first finding the bounding boxes then converting each cropped image to grayscale. After preprocessing all the images\n                of the dataset, we began researching into how convolutional neural network are structured and how to set up each layer for our projects. Implementing and understanding the neural network has been the biggest obstacle so far as it is all of our group members' first time working with neural networks.\n                We researched through various research papers and tutorials and have set up the network conceptually but are still in progress of coding the network.<br></br>\n                </Typography>\n\n\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Experimental and Qualitative Results \n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                We are working with the first section of the SVHN dataset, where we have 248,823 images with their respective digit bounding boxes and labels. As described in our approach, we began by preprocessing the .mat file similar to PS4,\n                loading out the bounding box information as well as the labels for the digits in each image. We stored these data as a pandas dataframe for the ease of access.  The dataframe contained the filename, four extremes of the bounding boxes, labels of the digits,\n                number of digits, the 30% increase value, as well as the original image dimensions. We then resized each individual image to 32x32 pixels as inputs to our neural network. Shown below are the outputs after cropping and resizing. <br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={cropped} alt=\"...\"></img>\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                After ensuring that we have successfully cropped, resized, and labeled our images, we decided to create a set of 6000 images as the validation set that can represent our dataset.\n                The validation set is used to evalute the given model, it will provide an unbiased evaluation of a model fit on the training dataset while tuning the hyperparameters. We take 4000 samples \n                from training set and 2000 samples from the extra set. We plotted the digit length distribution and individual digit distribution to ensure that the validation set is a reasonable representation \n                of our samples. We then combined all the images that are not a part of the validation set from training and extra into the final training set as the input to our neural network. The testing set is left\n                as it is.<br></br>\n                </Typography>\n            </Box>\n            <Typography>\n                Digit Length Distribution\n            </Typography>\n            <img className={classes.imageFormat} src={digitLengthDist} alt=\"...\"></img>\n\n            <Typography>\n                Idividual Digit Distribution\n            </Typography>\n            <img className={classes.imageFormat} src={individualDist} alt=\"...\"></img>\n\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                Shown below is an example of 25 images after the grayscale as well as the mean subtraction processing. \n                These are the images that will be the input to the neural network.<br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={gray} alt=\"...\"></img>\n\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                After the preprocessing, we will be trying to implement the neural network as the next step. First, we had to research more about \n                neural networks as none of us have worked with one before. We decided that we will be implementing a 9 layer convolutional neural netwrok with the following \n                architecture: <br></br>\n                </Typography>\n                <Typography align='center' variant='subtitle2' className={classes.titleParagraphFormat2}>\n                INPUT -{'>'} [[CONV -{'>'} RELU]*2 -{'>'} POOL]*2 -{'>'} [[CONV -{'>'} RELU]*3 -{'>'} POOL] -{'>'} [FC -{'>'} RELU]*2 -{'>'} OUTPUT<br></br>\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                CONV represents a convolution layer, which uses filters to perform convolution operations with filter size F and stride S to produce the feature map.\n                For our convolution layer, we are using a 5x5 filter as it provides a measurer for rhow close a patch of input resembles a feature, the weights in the filter\n                matrix are derived while training the data. We will use Rectified Linear Unit (RELU) as our activation function, it aims at introducing non-linearities to the network. As our input data is of size 32x32, with 1-5 digits within one input, a small filter of size 5x5 would be\n                more appropriate to collect representative information. The number of channels will be 1 as it should be equal to the number of color channels for the input, and \n                our images are in gray-scale. The first 7 layers of the network are CONV-RELU layers and POOL layers. The number of filters for the first two layers are of 32, next three layers are of 64, and the next two are of 128.\n                We increase the number as to increase the depth of the feature space, such that we can learn more levels of global abstract features. We set padding = same as the borders\n                of the image is important and we also want to perform more convolutions without shrinking size. <br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={conv} alt=\"...\"></img>\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                POOL represents a pooling layer, which is a downsampling operation to perform spatial invariance. We will be using max-pooling layers to down-sample the \n                input representation and reduce the input's dimensionality while keeling its max values (activated features).<br></br>\n                </Typography>\n            </Box>\n\n            <img className={classes.imageFormat} src={pool} alt=\"...\"></img>\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                FC represents a fully connected layer, which operatres on a flattened\n                input where each input is connected to all neurons. The FC layer is at the end of the architecture and is used to optimize certain objectives. <br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={fc} alt=\"...\"></img>\n\n            <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                We are currently still in the process of setting up our neural network based on the plan above. We will be using a loss function by taking the \n                average loss of every individual example for each of the 5 possible digits and sum them. This will be the cost function that we will be trying to minimize.\n                We will likely be using Adam as the optimizer but futher research needs to be done. We plan to evaluate the performance of our neural network by calculating the \n                average accuracy across all samples.<br></br>\n                </Typography>\n\n                <Typography align = 'center' variant = 'h4' className={classes.titleFormat}>\n                    Conclusion and Future Work\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                We are still at the most important part of the project, and the results have not been presented as our neural network is not fully set up so we have not trained our dataset.\n                This will be the next step to our project, after training our neural network, we will be using the optimization algorithm mentioned above and then evaluate the performance for the \n                final update. We will also continue to look into other potential preprocessing techniques other than mean-subtraction. At the midterm point, we find ourselves slightly behind where we wanted\n                to be due to the complexity of neural network. But we believe we understand how to set up each layer and tune the hyperparameters and we will soon be training our network. More details on\n                performance will be included in the final update.<br></br><br></br><br></br>\n                </Typography>\n            </Box>\n\n            \n        </div>\n    )\n}\n\nexport default MidtermUpdate;","import React from 'react';\n\nimport { Typography, Box } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header } from '../../components';\n//import { Link } from 'react-router-dom';\n\n\nimport teaser from \"../../img/teaser.png\";\nimport oneHot from \"../../img/oneHot.png\";\nimport softmax from \"../../img/softmax.png\";\nimport model from \"../../img/model.png\";\nimport train from \"../../img/train.png\";\nimport epoch from \"../../img/epoch.png\";\nimport correct from \"../../img/correct.png\";\nimport wrong from \"../../img/wrong.png\";\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'20px'\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n    boxFormat: {\n        width: '70%',\n        //paddingBottom:'20px',\n    },\n    titleFormat: {\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    lateTitleFormat: {\n        paddingTop: '20px',\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    titleParagraphFormat: {\n        fontFamily: '-apple-system',\n    },\n    titleParagraphFormat2: {\n        fontFamily: '-apple-system',\n        padding:'10px',\n    },\n    imageFormat: {\n        //paddingBottom:'20px',\n    },\n    imageFormat2: {\n        paddingBottom:'30px',\n    },\n    imageFormat3: {\n        paddingTop:'20px',\n    },\n}));\n\nconst FinalUpdate = ({ tagChange }) => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Box className={classes.boxFormat}>\n\n\n                <Typography align = 'center' variant = 'h4' className={classes.titleFormat}>\n                    Abstract\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat}>\n                The goal of our project is to train a convolutional neural network (CNN) to detect the digits of a house number displayed on the streets. \n                This is a basic image recognition that can be useful in many different fields. We were able to train our neural network to perform multi-digit recognition with an accuracy rate of 94.2%.<br></br><br></br>\n                </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={teaser} alt=\"...\"></img>\n            <Box className={classes.boxFormat}>\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Introduction\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                As shown in the image above, our project targets images of house numbers displayed on the streets, \n                we hope to achieve reasonable results given a variety of resolutions of the images. \n                Digit recognition is becoming increasingly important in various domains as technology advances. \n                Whether it is a mapping company needing to match images of house numbers to their geolocations, \n                or a robot trying to locate itself through room numbers/house numbers, \n                SVHN serves as a good basic dataset to dive into the world of image recognition. \n                We wanted to implement our project from scratch to understand how to preprocess the dataset as well as \n                to gain a deeper understanding of how to set up and train our own neural network. \n                Most existing ways of recognizing street view house numbers include two steps after locating where the numbers are within a picture: \n                slicing each digit and recognizing. The ways some other projects built the neural network rely on preprocessing the picture to make boxes around each digit, \n                and can only recognize individual digits. The output layers of their convolutional neural networks have 11 neurons, \n                each corresponding to a possible digit (ten of which represent zero to nine, and the last one represent none). \n                Our approach only has one step after locating the numbers in the pictures. We directly feed the portion of the image with all the numbers into the network, \n                and train the network to predict all of the numbers at the same time.\n                </Typography>\n\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Approach\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                The first step was to preprocess the data from <a href=\"http://ufldl.stanford.edu/housenumbers/\">The Street View House Numbers (SVHN) Dataset</a>. We first focused on the first part of the dataset, where colored house-number images are given, and the bounding box for each digit is given in a .mat file. The general steps we took to preprocess the image dataset are to: limit the maximum number of digit to 5 (there is only one image that has 6 digits in the picture), make a new bounding box given the min and max values of the x and y values for all bounding boxes of all digits, expand the bounding box in each direction by 30% to ensure the coverage of all digit details. After preprocessing all the images of the dataset, we chose to use Tensorflow.Keras to help us construct the CNN as it has many predefined methods to build the architecture. <br></br><br></br>\n                As introduced in the midterm update, we were able to preprocess the images and store them in a .h5 file. The data contains cropped street view house number images of size 32x32 and their corresponding labels in the form of 5 elements lists. Each of these label lists contains 5 integers, ranging from 0 to 10, with 0 to 9 representing the actual number shown in the image, and 10 being a placeholder for images that have less than 5 numbers (If \"19\" appears in the image, the label list would be: [1, 9, 10, 10, 10]). To construct the CNN architecture, we began by defining the input and output layers. Our input would be the preprocessed images, which have size 32x32x3. Finding the way to construct the output layer was less intuitive for us. Common classification CNN selects and condenses important features in hidden layers, and makes the number of neurons on the output layer correspond to the number of classes the data belongs to. In this case, as each element in our labels ranges from 0 to 10, there should be 11 classes, which correspond to 11 neurons on the output layer, and the list containing the correct information for the output layer to compare with should contain 11 elements. This does not coincide with our label data set, as each of these label lists contain 5 elements. Therefore, we first further processed our labels and converted them using the one-hot encoding method. Each of these 5x1 label lists then becomes a 5x11 list, with ten 0s and one 1 located on the index corresponding to this label. Shown below is an example of how the label \"19\" is represented in the original label list as well as the one-hot format. <br></br>\n                </Typography>\n        </Box>\n        <Typography>One-Hot Encoding</Typography>\n        <img className={classes.imageFormat} src={oneHot} alt=\"...\"></img>\n        <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                With the help of this, we further designed the output layer of the network to also be in the dimension of 5x11. \n                We individually connected 5 separate softmax densely-connected layers with 11 neurons each to their previous common fully connected layer. \n                Then we concatenated them and reshaped them into the size of 5x11.<br></br>\n                </Typography>\n        </Box>\n        <Typography>Design of Output Layer</Typography>\n        <img className={classes.imageFormat2} src={softmax} alt=\"...\"></img>\n        <Box className={classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                After settling down our input and output layers, we started to construct the hidden layers. Considering that our dataset is only recognizing numbers, which do not have very complex featured shapes and patterns, but there are 11 possible categories, we decided to use 3 convolutional layers, each is followed by 3 pooling layers, and there are 2 fully connected layers at the end. For each of these convolutional layers, we used Rectified Linear Unit(ReLU) as our activation function, as it allows an arbitrary amount of output, which corresponds to our scenario of wanting to classify into many classes. The convolutional layers have 64, 128, 256 filters, with a 7x7, 5x5, 3x3 dimension of kernel respectively. As the dimension of the kernel represents the height and width of the 2D convolution window, we decided to gradually decrease it while increasing the amount of filters to capture more essential details. As for padding, we wanted the results coming out from the first layer to preserve spatial dimensions of the volume, so we set padding to be the same for the first layer. For the second and the third, as the layers gradually identified important features, we set the padding to valid to allow the spatial dimensions to reduce via the natural application of convolution.\n                <br></br>\n                <br></br>\n                Before each of these convolutional layers, we performed a batch normalization to preprocess their input, reduce the internal covariate shift, and increase the learning efficiencies. Following each convolutional layer, we used Max Pooling with a size of 2x2 to reduce the spatial dimensions of the output volume. After this, we wanted to increase the challenges for the network to learn the data by randomly dropping out some neurons on each layer, so we made each of these max pooled layers dropout with a rate of [0.3, 0.3, 0.5] respectively. For the fully connected layers. We first flattened the data and then applied two fully connected layers with sizes 1024 and 512, using them to combine the features and prepare for the final output.\n                <br></br>\n                </Typography>\n\n        </Box>\n        <Box className = {classes.boxFormat}>\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Experimental and Qualitative Results\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                The input to the CNN is a set of 32x32x3 images, we conducted trials on black and white images first and found similar rates of success, we will be displaying the results of training and testing on colored images as this is more realistic and we do not expect users to preprocess images to black and white before using our model. Shown below is an image of the neural network model summary, showing the various layers and shapes.\n                </Typography>\n        </Box>\n        <Typography>Model Summary</Typography>\n        <img className={classes.imageFormat3} src={model} alt=\"...\"></img>\n        <Box className = {classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                After setting up our neural network as above, we spent a lot of time tuning the various things such as the number of drop out layers, the batch size, and the number of epochs ran. We found out that having more dropout layers increases the accuracy as the act of randomly dropping neurons increases the challenge for the network to learn the data, making the network record more essential details, and thus increasing its ability for generalization. The batch size was closely related to the number of epochs, as we realized that for a smaller batch size, a smaller value for epoch should be chosen for higher accuracy. We tested batch sizes of 16 and 64, varying the epoch value between 3, 19, 15, and 20. In the end, we chose a batch size of 64 and epoch value of 10 with the lowest loss towards the end and maximum accuracy. We tested two optimizers: Adam and Root Mean Square Propagation (RMSProp). We chose RMPSprop in the end as it tries to dampen the oscillations and automatically adjust the learning rates.\n                </Typography>\n        </Box>\n        <Typography><br></br>Training Process</Typography>\n        <img className={classes.imageFormat3} src={train} alt=\"...\"></img>\n        \n        <Box className = {classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                As shown above, the accuracy increased as the loss decreased throughout the training. We decided that 10 epochs was the right value for a batch size of 64 as we realized beyond 10 epochs the loss started to increase and the accuracy decreased. The graphs for Epoch vs. accuracy/loss are shown below.\n                </Typography>\n        </Box>\n\n        <Typography><br></br>Accuracy and Loss</Typography>\n        <img className={classes.imageFormat3} src={epoch} alt=\"...\"></img>\n\n        <Box className = {classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                After evaluating our model with the testing dataset, we were able to achieve a rate of 94.2%. We then plotted some images along with their respective true and predicted labels to see the performance of our trained neural network. Shown below are 25 of correct predictions and 25 of wrong predictions. The wrongly predicted images show that our network struggled to distinguish between 1 and 7 and missed some digits at times. There seem to be some errors in the original labelling, which could have affected our model.\n                <br></br>\n                </Typography>\n        </Box>\n\n        <Typography>Correct Predictions</Typography>\n        <img className={classes.imageFormat3} src={correct} alt=\"...\"></img>\n        <Typography><br></br>Wrong Predictions</Typography>\n        <img className={classes.imageFormat3} src={wrong} alt=\"...\"></img>\n\n        <Box className = {classes.boxFormat}>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                These results are as expected, as the image resolution is not high, and with the images taken at different angles, it could even be hard for a human to recognize the number shown. Since we are not trying to detect the digits one by one, we don't expect our model to predict the correct number of digits for every image, as background details could be misidentified as a number potentially. Compared to a naive approach, which could perhaps make random decisions to predict the digits, our model performs much better. If the algorithm is to randomly predict the digits, the rate would be 1/(11)^N for N digits as there are a total of 11 digit possibilities (0 to 9, and None).\n                <br></br>\n                </Typography>\n        </Box>\n\n        <Box className = {classes.boxFormat}>\n                <Typography align = 'center' variant = 'h4' className={classes.lateTitleFormat}>\n                    Conclusion and Future Work\n                </Typography>\n                <Typography align='left' variant='subtitle1' className={classes.titleParagraphFormat2}>\n                Being the first CNN we have designed from scratch, we are reasonably satisfied with an accuracy of 94.2%. For future work, we believe that our model can be extended and the parameters can be tuned for better accuracy. As time was limited, we did not tune the parameters as much as we would have liked. Preprocessing could also be improved by improving the potential lighting/angle of the images. By preprocessing the images further, we could enhance some of the details of the digits and reduce the impact of background details on training. Having some problems predicting the correct number of digits was a problem as our model does not predict digit by digit but rather the entire number at once. Overall, we believe that this project has been a success.<br></br><br></br><br></br>\n                </Typography>\n        </Box>\n        \n\n        \n        </div>\n    )\n}\n\nexport default FinalUpdate;","import React from 'react';\n\nimport { Typography } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header } from '../../components';\n//import { Link } from 'react-router-dom';\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'10%'\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n}));\n\nconst ProjectVideo = ({ tagChange }) => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Typography>\n                In progress\n            </Typography>\n        </div>\n    )\n}\n\nexport default ProjectVideo;","import React from 'react';\n\nimport { Typography, Box } from '@material-ui/core';\nimport { makeStyles } from '@material-ui/core/styles';\nimport { Header } from '../../components';\n//import { Link } from 'react-router-dom';\n\nimport ref from \"../../img/references.png\";\n\nconst useStyles = makeStyles((theme) => ({\n    wrapper: {\n        display: 'flex',\n        alignItems: 'center',\n        flexDirection:'column',\n        paddingTop:'2%'\n    },\n    link: {\n        textDecoration: 'none',\n        color: '#000',\n    },\n    titleFormat: {\n        paddingBottom:'10px',\n        textDecoration: \"none\",\n        color:'#212F3C',\n        //fontFamily: '-apple-system',\n    },\n    paragraphFormat: {\n        fontFamily: '-apple-system',\n    },\n    boxFormat: {\n        width: '70%',\n    },\n}));\n\nconst References = ({ tagChange }) => {\n    const classes = useStyles();\n    //const theme = useTheme();\n\n\n\n    return (\n        <div className={classes.wrapper}>\n            <Header></Header>\n            <Box className={classes.boxFormat}>\n            <Typography align = 'center' variant = 'h4' className={classes.titleFormat}>\n                References\n            </Typography>\n            </Box>\n            <img className={classes.imageFormat} src={ref} alt=\"...\"></img>\n        </div>\n    )\n}\n\nexport default References;","//add the following into package.json\n//npm run build\nimport React from 'react';\nimport { createMuiTheme } from '@material-ui/core/styles';\nimport { ThemeProvider } from '@material-ui/core';\nimport { Route, Switch } from 'react-router-dom';\n\nimport { Landing, MidtermUpdate, ProjectVideo, FinalUpdate, Proposal, References } from './pages';\n\nimport styles from './App.css';\n\nconst theme = createMuiTheme({\n  palette: {\n      primary: {\n          // light: will be calculated from palette.primary.main,\n          main: '#000000',\n          // dark: will be calculated from palette.primary.main,\n          // contrastText: will be calculated to contrast with palette.primary.main\n      },\n      secondary: {\n          main: '#FCFFFF',\n          // dark: will be calculated from palette.secondary.main,\n          contrastText: '#ffcc00',\n      },\n      // Used by `getContrastText()` to maximize the contrast between\n      // the background and the text.\n      contrastThreshold: 3,\n      // Used by the functions below to shift a color's luminance by approximately\n      // two indexes within its tonal palette.\n      // E.g., shift from Red 500 to Red 300 or Red 700.\n      tonalOffset: 0.2,\n  },\n  typography: {\n      fontFamily: [\n          '\"Space Mono\"',\n          // 'Ubuntu',\n          // 'MuseoModerno',\n          // 'Notable',\n          // '\"Space Mono\"',\n          // 'Roboto',\n          // '\"Helvetica Neue\"',\n          // 'Arial',\n          // 'sans-serif',\n          // '\"Apple Color Emoji\"',\n          // '\"Segoe UI Emoji\"',\n          // '\"Segoe UI Symbol\"',\n        ].join(','),\n    },\n});\n\nclass App extends React.Component {\n  render() {\n      return (\n          <main>\n              <ThemeProvider theme={theme}>\n                  <Switch>\n                      <Route exact path={`/`} component={Landing} /*exact*/ />\n                      <Route exact path={`/proposal`} render={() => <Proposal/>} />\n                      <Route exact path={`/midtermUpdate`} render={() => <MidtermUpdate/>} />\n                      <Route exact path={`/finalUpdate`} render={() => <FinalUpdate/>} />\n                      <Route exact path={`/projectVideo`} render={() => <ProjectVideo/>} />\n                      <Route exact path={`/references`} render={() => <References/>} />\n                  </Switch>\n              </ThemeProvider>\n          </main>\n      )\n  }\n}\nexport default App;","import React from 'react';\nimport ReactDOM from 'react-dom';\n\nimport { HashRouter } from 'react-router-dom';\n\nimport App from './App';\n\nReactDOM.render(\n    <HashRouter basename={process.env.PUBLIC_URL}>\n        <App />\n    </HashRouter>, \n    document.getElementById('root')\n)"],"sourceRoot":""}